{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import pathlib\n",
    "import altair as alt\n",
    "import arviz as az\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as p9\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(config, df, name, config_map={}):\n",
    "    data_df = df.loc[df['data_name'] == name, :].copy()\n",
    "\n",
    "    for config_name, col_name in config_map.items():\n",
    "        data_df.loc[:, col_name] = data_df['data_id'].apply(lambda id: config[id][config_name])\n",
    "\n",
    "    return data_df\n",
    "\n",
    "def aggregate_results(df, group_cols, metric_cols, functions={'mean': ['mean'], 'median': ['median'], 'std': ['std'], 'q25': ['quantile', 0.25], 'q75': ['quantile', 0.75]}):\n",
    "    summary_df = pd.DataFrame({col: [] for col in group_cols + ['variable']})\n",
    "    groups_df = df.groupby(group_cols)\n",
    "\n",
    "    for col, args in functions.items():\n",
    "        tmp_df = groups_df[metric_cols].agg(*args).reset_index()\n",
    "        summary_df = summary_df.merge(\n",
    "            pd.melt(tmp_df, id_vars=group_cols, value_vars=metric_cols, value_name=col),\n",
    "            on=group_cols + ['variable'],\n",
    "            how='outer'\n",
    "        )\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figure_size(width=None, height=None, ratio=None):\n",
    "    match (width, height, ratio):\n",
    "        case (None, None, None):\n",
    "            raise ValueError('Invalid figure size parameters')\n",
    "        case (width, height, None) if width is not None and height is not None:\n",
    "            return (width, height)\n",
    "        case (width, None, ratio) if width is not None and ratio is not None:\n",
    "            return (width, width * ratio)\n",
    "        case (None, height, ratio) if height is not None and ratio is not None:\n",
    "            return (height / ratio, height)\n",
    "        case _:\n",
    "            raise ValueError('Invalid figure size parameters')\n",
    "\n",
    "def aggregated_results_plot(df, name, x_col, y_col='median', y_min_col='q25', y_max_col='q75', model_col='model_name', var_col='variable',\n",
    "    model_color_map=None, facet_cols=None, model_name_map=None, variable_map=None, facet_maps=None, scale_x_map=None, scale_x=None, labs={},\n",
    "    facet_ncol=3, y_labels=True, y_limits=(0.0, None), figure_size=get_figure_size(width=6, ratio=2/3), dpi=300, errorbar_width=0.05, default_parameters=None,\n",
    "    default_shape_map={'Default': 'x'}, model_shape_map=None, panel_spacing=0.025, facet_scales='fixed', guide_kwargs=None, default_y_lab='Distance metric',\n",
    "    scale_y=None, dodge_width=0.2, ncol=7\n",
    "):\n",
    "    df = df.copy()\n",
    "\n",
    "    if model_name_map is not None:\n",
    "        df = df[df[model_col].isin(model_name_map.keys())].copy()\n",
    "        df[model_col] = pd.Categorical(df[model_col].map(model_name_map), model_name_map.values())\n",
    "\n",
    "        if model_color_map is not None:\n",
    "            model_color_map = {model_name_map[k]: v for k, v in model_color_map.items() if k in model_name_map.keys()}\n",
    "\n",
    "        if model_shape_map is not None:\n",
    "            model_shape_map = {model_name_map[k]: v for k, v in model_shape_map.items() if k in model_name_map.keys()}\n",
    "\n",
    "    if variable_map is not None:\n",
    "        df = df[df[var_col].isin(variable_map.keys())].copy()\n",
    "        df[var_col] = pd.Categorical(df[var_col].map(variable_map), variable_map.values())\n",
    "\n",
    "    shape_map = model_shape_map if model_shape_map is not None else {}\n",
    "\n",
    "    df['point_shape'] = df[model_col].copy()\n",
    "\n",
    "    if default_parameters is not None:\n",
    "        if x_col in default_parameters:\n",
    "            df['is_default'] = df[x_col] == default_parameters[x_col]\n",
    "            df['point_shape'] = np.where(df['is_default'], 'Default', df['point_shape'])\n",
    "            shape_map = default_shape_map | shape_map\n",
    "            df['point_shape'] = pd.Categorical(df['point_shape'], shape_map.keys())\n",
    "        elif facet_cols is not None and np.all([col in default_parameters for col in facet_cols]):\n",
    "            df['is_default'] = True\n",
    "\n",
    "            for col in facet_cols:\n",
    "                df['is_default'] = np.logical_and(df['is_default'], df[col].apply(lambda x: x == default_parameters[col]))\n",
    "\n",
    "            df['point_shape'] = np.where(df['is_default'], 'Default', df['point_shape'])\n",
    "            shape_map = default_shape_map | shape_map\n",
    "            df['point_shape'] = pd.Categorical(df['point_shape'], shape_map.keys())\n",
    "\n",
    "    if scale_x_map is not None:\n",
    "        df = df[df[x_col].isin(scale_x_map.keys())].copy()\n",
    "        df[x_col] = pd.Categorical(df[x_col].map(scale_x_map), scale_x_map.values())\n",
    "\n",
    "    if facet_cols is not None:\n",
    "        for facet_col in facet_cols:\n",
    "            if facet_col not in facet_maps:\n",
    "                continue\n",
    "\n",
    "            facet_map = facet_maps[facet_col]\n",
    "            df = df[df[facet_col].isin(facet_map.keys())].copy()\n",
    "            df[facet_col] = pd.Categorical(df[facet_col].map(facet_map), facet_map.values())\n",
    "\n",
    "    if x_col == model_col:\n",
    "        df['constant'] = 'constant'\n",
    "        p = p9.ggplot(df, p9.aes(x='constant', y=y_col, color=model_col, group=model_col))\n",
    "    else:\n",
    "        p = p9.ggplot(df, p9.aes(x=x_col, y=y_col, color=model_col, group=model_col))\n",
    "\n",
    "    if facet_cols is not None and len(facet_cols) > 1:\n",
    "        if x_col == model_col:\n",
    "            df_cols = [x_col, 'constant']\n",
    "        else:\n",
    "            df_cols = [x_col]\n",
    "\n",
    "        df_default_y = df.loc[df['is_default'], facet_cols + df_cols + [y_col]].copy()\n",
    "        df_default = pd.merge(df.loc[:,facet_cols + df_cols], df_default_y, on=df_cols, how='left')\n",
    "        p = p + p9.geom_point(p9.aes(x='constant', y=y_col), size=2, position=p9.position_dodge(width=dodge_width), shape=shape_map['Default'], color='gray', alpha=0.5, data=df_default)\n",
    "\n",
    "    p = p + p9.geom_line()\n",
    "\n",
    "    if y_min_col in df.columns and df[y_min_col].notna().any():\n",
    "        if x_col == model_col:\n",
    "            p = p + p9.geom_errorbar(p9.aes(ymin=f'{y_min_col}', ymax=f'{y_max_col}'), width=errorbar_width, position=p9.position_dodge(width=dodge_width))\n",
    "        else:\n",
    "            p = p + p9.geom_errorbar(p9.aes(ymin=f'{y_min_col}', ymax=f'{y_max_col}'), width=errorbar_width)\n",
    "\n",
    "    if x_col == model_col:\n",
    "        p = p + p9.geom_point(p9.aes(shape='point_shape'), size=2, position=p9.position_dodge(width=dodge_width))\n",
    "    else:\n",
    "        p = p + p9.geom_point(p9.aes(shape='point_shape'), size=2)\n",
    "\n",
    "    if df[var_col].nunique() > 1:\n",
    "        if facet_cols is not None and len(facet_cols) == 1:\n",
    "            p = p + p9.facet_grid(f'{facet_cols[0]} ~ {var_col}', scales=facet_scales)\n",
    "        else:\n",
    "            p = p + p9.facet_wrap(f'~{var_col}', scales=facet_scales, ncol=facet_ncol)\n",
    "    elif facet_cols is not None:\n",
    "        assert len(facet_cols) < 3, 'Only up to two facet columns are supported'\n",
    "\n",
    "        if len(facet_cols) == 1:\n",
    "            p = p + p9.facet_wrap(f'~{facet_cols[0]}', scales=facet_scales, ncol=facet_ncol)\n",
    "        else:\n",
    "            p = p + p9.facet_grid(f'{facet_cols[0]} ~ {facet_cols[1]}')\n",
    "\n",
    "    if scale_y == 'sqrt':\n",
    "        p = p + p9.scale_y_sqrt(labels=y_labels)\n",
    "    elif scale_y == 'log':\n",
    "        p = p + p9.scale_y_log10(labels=y_labels)\n",
    "    else:\n",
    "        p = p + p9.scale_y_continuous(labels=y_labels)\n",
    "\n",
    "    if y_limits is not None:\n",
    "        p = p + p9.coord_cartesian(ylim=y_limits)\n",
    "\n",
    "    if x_col != model_col:\n",
    "        if scale_x == 'sqrt':\n",
    "            p = p + p9.scale_x_sqrt()\n",
    "        elif scale_x == 'log':\n",
    "            p = p + p9.scale_x_log10()\n",
    "\n",
    "    if model_color_map is not None:\n",
    "        p = p + p9.scale_color_manual(breaks=list(model_color_map.keys()), values=list(model_color_map.values()))\n",
    "\n",
    "    if shape_map:\n",
    "        p = p + p9.scale_shape_manual(breaks=[k for k in shape_map.keys() if k != 'Default'], values=list(shape_map.values()))\n",
    "\n",
    "    default_labs = {'shape': '', 'color': ''}\n",
    "\n",
    "    if len(variable_map) > 1:\n",
    "        default_labs['y'] = default_y_lab\n",
    "    else:\n",
    "        default_labs['y'] = next(iter(variable_map.values()))\n",
    "\n",
    "    p = p + p9.labs(**(default_labs | labs))\n",
    "\n",
    "    p = (p\n",
    "        + p9.theme_minimal()\n",
    "        + p9.theme(\n",
    "            panel_spacing=panel_spacing, \n",
    "            legend_position='bottom',\n",
    "            #legend_text=p9.element_text(size=8), \n",
    "            figure_size=figure_size, \n",
    "            dpi=dpi,\n",
    "            panel_background=p9.element_rect(fill='white',color='white'),\n",
    "            plot_background=p9.element_rect(fill='white',color='white'),\n",
    "            \n",
    "        )\n",
    "    )\n",
    "\n",
    "    p += p9.guides(color=p9.guide_legend(ncol=ncol), shape=p9.guide_legend(ncol=ncol))\n",
    "\n",
    "    if x_col == model_col:\n",
    "        p = p + p9.theme(axis_text_x = p9.element_blank())\n",
    "\n",
    "    if guide_kwargs is not None:\n",
    "        p = p + p9.guides(**guide_kwargs)\n",
    "\n",
    "    if not pathlib.Path(f'../tmp/figures').exists():\n",
    "        pathlib.Path(f'../tmp/figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    p.save(f'../tmp/figures/{name}.png')\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to mark the default option on the plot with gray \"X\"\n",
    "default_parameters = {\n",
    "    'agg_bias': 0.0,\n",
    "    'data_has_selection': True,\n",
    "    'data_int': False,\n",
    "    'error_distribution': 'normal',\n",
    "    'heckman_coef_rho': 0.0,\n",
    "    'heckman_rho': 0.5,\n",
    "    'model_int': False,\n",
    "    'model_margin': 'unit',\n",
    "    'model_prior_scale': False,\n",
    "    'sample_size': 1000,\n",
    "    'selection_bias': 0.0,\n",
    "    'selection_intercept': -1.0,\n",
    "    'selection_noise_prop': 0.0,\n",
    "    'selection_prop': 0.2103,\n",
    "    'selection_sigma': 0.5,\n",
    "    'selection_skew': 0.0,\n",
    "    'outcome_noise_prop': 0.0,\n",
    "    'outcome_skew': 0.0,\n",
    "    'outcome_sigma': 0.5,\n",
    "    'overreport_prop': 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2821ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = json.load(open('../tmp/data/data_list.json', 'r'))\n",
    "data_config = {name: config for config_list in data_list.values() for name, config in config_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_df = pd.read_csv('../tmp/models/model_results.csv', index_col=0)\n",
    "model_results_df['seed'] = model_results_df['data_id'].apply(lambda id: str(data_config[id].get('seed')))\n",
    "print(model_results_df.shape)\n",
    "print(model_results_df['data_name'].unique())\n",
    "model_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06344630",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_name_map = {\n",
    "    '3_gg': 'default',\n",
    "    '3_int_gg': 'int',\n",
    "    '3_tpl_gg': 'tpl',\n",
    "    '3_electoral_district_gg': 'electoral_district',\n",
    "    '3_unit_gg': 'unit',\n",
    "    '5_fs': 'default',\n",
    "    '5_int_fs': 'int',\n",
    "    '5_tpl_fs': 'tpl',\n",
    "    '5_electoral_district_fs': 'electoral_district',\n",
    "    '5_unit_fs': 'unit',\n",
    "}\n",
    "\n",
    "data_name_blacklist = ['est-no-selection']\n",
    "\n",
    "metric_cols = ['kld', 'kld_1d', 'kld_2d', 'emd', 'emd_1d', 'emd_2d']\n",
    "\n",
    "comparison_models_df = model_results_df[model_results_df['model_name'].isin(comparison_name_map.keys())].copy()\n",
    "comparison_models_df['category'] = comparison_models_df['model_name'].apply(lambda x: comparison_name_map[x])\n",
    "comparison_models_summary_df = comparison_models_df.groupby(['data_name', 'model_name', 'category'])[metric_cols].median()\n",
    "comparison_models_summary_df = comparison_models_summary_df.reset_index().set_index('model_name')\n",
    "comparison_gg_models_df = comparison_models_summary_df.loc[comparison_models_summary_df.index.str.contains('gg')].reset_index()\n",
    "comparison_fs_models_df = comparison_models_summary_df.loc[comparison_models_summary_df.index.str.contains('fs')].reset_index()\n",
    "comparison_models_summary_df = pd.merge(comparison_gg_models_df, comparison_fs_models_df, on=['data_name', 'category'], suffixes=('_gg', '_fs'))\n",
    "comparison_models_summary_df = comparison_models_summary_df[~comparison_models_summary_df['data_name'].isin(data_name_blacklist)]\n",
    "\n",
    "for col in metric_cols:\n",
    "    comparison_models_summary_df[col] = comparison_models_summary_df[f'{col}_fs'] / comparison_models_summary_df[f'{col}_gg'] - 1\n",
    "#comparison_models_summary_df[metric_cols].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "#comparison_models_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7013bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(all_map, names):\n",
    "    return {k: v for k, v in all_map.items() if k in names}\n",
    "\n",
    "model_name_all_map = {\n",
    "    '1_bp': 'BP model',\n",
    "    '2_ei': 'EI model',\n",
    "    '3_gg': 'GG model',\n",
    "    '4_pm': 'PM model',\n",
    "    '5_fs': 'FS model'\n",
    "}\n",
    "\n",
    "model_name_map = get_map(model_name_all_map, ['3_gg', '4_pm', '5_fs'])\n",
    "\n",
    "variable_all_map = {\n",
    "    'kld': 'Full margin $D_{KL}$',\n",
    "    'kld_1d': '1D margin median $D_{KL}$',\n",
    "    'kld_2d': '2D margin median $D_{KL}$',\n",
    "    'emd': 'Full margin $D_{EM}$',\n",
    "    'emd_1d': '1D margin median $D_{EM}$',\n",
    "    'emd_2d': '2D margin median $D_{EM}$'\n",
    "}\n",
    "\n",
    "model_color_map = {\n",
    "    '1_bp': '#e41a1c',\n",
    "    '2_ei': '#377eb8',\n",
    "    '3_gg': '#4daf4a',\n",
    "    '4_pm': '#984ea3',\n",
    "    '5_fs': '#ff7f00'\n",
    "}\n",
    "model_shape_map = {\n",
    "    '1_bp': 'o',\n",
    "    '2_ei': '^',\n",
    "    '3_gg': 's',\n",
    "    '4_pm': 'D',\n",
    "    '5_fs': 'v'\n",
    "}\n",
    "\n",
    "variable_map = get_map(variable_all_map, ['kld_2d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc91804",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df = get_results(data_config, model_results_df, 'est-default')\n",
    "default_summary_df = aggregate_results(default_df, ['data_name', 'model_name'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    default_summary_df,\n",
    "    'default_parameters_linear',\n",
    "    'model_name',\n",
    "    model_name_map=model_name_all_map, variable_map=get_map(variable_all_map, ['kld', 'kld_1d', 'kld_2d', 'emd', 'emd_1d', 'emd_2d']),\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': '', 'y': 'Distance from ground truth'},\n",
    "    errorbar_width=0.2,\n",
    "    figure_size=get_figure_size(width=7, ratio=2/3),\n",
    "    default_parameters=default_parameters,\n",
    "    facet_scales='free_y',\n",
    "    ncol=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results_plot(\n",
    "    default_summary_df,\n",
    "    'default_parameters',\n",
    "    'model_name',\n",
    "    model_name_map=model_name_all_map, variable_map=get_map(variable_all_map, ['kld', 'kld_1d', 'kld_2d', 'emd', 'emd_1d', 'emd_2d']),\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': '', 'y': 'Distance from ground truth'},\n",
    "    errorbar_width=0.2,\n",
    "    figure_size=get_figure_size(width=7, ratio=2/3),\n",
    "    default_parameters=default_parameters,\n",
    "    facet_scales='free_y',\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.25), 10**(-0.5)),\n",
    "    ncol=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88d61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f189f5fd",
   "metadata": {},
   "source": [
    "### Aggregation bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd718f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_bias_df = get_results(data_config, model_results_df, 'est-agg-bias', {'aggregation_bias_kwargs/coefs': 'agg_bias'})\n",
    "agg_bias_df['agg_bias'] = agg_bias_df['agg_bias'].apply(lambda x: x['nationality']['Other'])\n",
    "agg_bias_summary_df = aggregate_results(agg_bias_df, ['model_name', 'agg_bias'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    agg_bias_summary_df,\n",
    "    'agg_bias',\n",
    "    'agg_bias',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Aggregation bias ($\\\\beta_{AB}$)'},\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.5))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533de908",
   "metadata": {},
   "source": [
    "### Selection bias / non-response bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555779f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_selection_df = pd.concat([\n",
    "    get_results(data_config, model_results_df, 'est-no-selection'),\n",
    "    get_results(data_config, model_results_df, 'est-default'),\n",
    "])\n",
    "no_selection_df['data_has_selection'] = no_selection_df['data_name'] == 'est-default'\n",
    "no_selection_summary_df = aggregate_results(no_selection_df, ['model_name', 'data_has_selection'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    no_selection_summary_df,\n",
    "    'no_selection',\n",
    "    'data_has_selection',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    scale_x_map={False: 'No selection effect', True: 'Selection effect'},\n",
    "    labs={'x': 'Selection effect in data'},\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.5)),\n",
    "    errorbar_width=0.10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_response_df = get_results(data_config, model_results_df, 'est-non-response', {'heckman_coef_kwargs/heckman_coefs/selection/intercept': 'selection_intercept'})\n",
    "\n",
    "selection_props = {}\n",
    "\n",
    "for data_id in non_response_df['data_id'].unique():\n",
    "    pop_df = pd.read_csv(f'../tmp/data/{data_id}/population.csv')\n",
    "    selection_prop = pop_df['selection'].sum() / len(pop_df)\n",
    "    selection_props[data_id] = selection_prop.round(3)\n",
    "\n",
    "non_response_df['selection_prop'] = non_response_df['data_id'].apply(lambda id: selection_props[id])\n",
    "non_response_summary_df = aggregate_results(non_response_df, ['model_name', 'selection_intercept'], list(variable_all_map.keys()))\n",
    "selection_prop_df = aggregate_results(non_response_df, ['model_name', 'selection_intercept'], ['selection_prop'], functions={'mean': ['mean']}).drop(columns=['variable']).rename(columns={'mean': 'selection_prop'})\n",
    "non_response_summary_df = pd.merge(non_response_summary_df, selection_prop_df, on=['model_name', 'selection_intercept'], how='left')\n",
    "\n",
    "aggregated_results_plot(\n",
    "    non_response_summary_df,\n",
    "    'non_response',\n",
    "    'selection_prop',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Proportion of available population for survey sampling'},\n",
    "    errorbar_width=0.025,\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.0)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afdb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_name_map = {\n",
    "    \"2_margin_tpl_ei\": \"2_ei\",\n",
    "    \"3_margin_tpl_gg\": \"3_gg\",\n",
    "    \"4_margin_tpl_pm\": \"4_pm\",\n",
    "    \"5_margin_tpl_fs\": \"5_fs\",\n",
    "    \"2_margin_electoral_district_ei\": \"2_ei\",\n",
    "    \"3_margin_electoral_district_gg\": \"3_gg\",\n",
    "    \"4_margin_electoral_district_pm\": \"4_pm\",\n",
    "    \"5_margin_electoral_district_fs\": \"5_fs\",\n",
    "    \"2_margin_unit_ei\": \"2_ei\",\n",
    "    \"3_margin_unit_gg\": \"3_gg\",\n",
    "    \"4_margin_unit_pm\": \"4_pm\",\n",
    "    \"5_margin_unit_fs\": \"5_fs\"\n",
    "}\n",
    "\n",
    "margin_map = {\n",
    "    \"2_margin_tpl_ei\": \"topline\",\n",
    "    \"3_margin_tpl_gg\": \"topline\",\n",
    "    \"4_margin_tpl_pm\": \"topline\",\n",
    "    \"5_margin_tpl_fs\": \"topline\",\n",
    "    \"2_margin_electoral_district_ei\": \"electoral_district\",\n",
    "    \"3_margin_electoral_district_gg\": \"electoral_district\",\n",
    "    \"4_margin_electoral_district_pm\": \"electoral_district\",\n",
    "    \"5_margin_electoral_district_fs\": \"electoral_district\",\n",
    "    \"2_margin_unit_ei\": \"unit\",\n",
    "    \"3_margin_unit_gg\": \"unit\",\n",
    "    \"4_margin_unit_pm\": \"unit\",\n",
    "    \"5_margin_unit_fs\": \"unit\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee66955",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_df = get_results(data_config, model_results_df, 'est-electoral-district')\n",
    "margin_df = margin_df[margin_df['model_name'].isin(margin_name_map.keys())]\n",
    "margin_df['model_margin'] = margin_df['model_name'].apply(lambda x: margin_map[x])\n",
    "margin_df['model_name'] = margin_df['model_name'].apply(lambda x: margin_name_map[x] if x in margin_name_map else x)\n",
    "\n",
    "margin_summary_df = aggregate_results(margin_df, ['model_name', 'model_margin'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    margin_summary_df,\n",
    "    'margin',\n",
    "    'model_margin',\n",
    "    model_name_map=get_map(model_name_all_map, ['2_ei', '3_gg', '4_pm', '5_fs', '6_afs', '7_oppm', '8_opafs']), variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Turnout margins used by model'},\n",
    "    scale_x_map={'topline': 'Topline', 'electoral_district': 'Electoral district', 'unit': 'Municipality'},\n",
    "    errorbar_width=0.05,\n",
    "    figure_size=get_figure_size(width=5, ratio=2/3),\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.25), 10**(-1.0)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478690cc",
   "metadata": {},
   "source": [
    "### Measurement bias / overreporting bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overreport_df = get_results(data_config, model_results_df, 'est-overreport-const', {'selection_kwargs/bias/offset': 'selection_bias', 'selection_kwargs/bias/type': 'selection_bias_type'})\n",
    "survey_cols = ['age_group', 'education', 'gender', 'nationality', 'electoral_district', 'unit', 'selection_error', 'outcome_error']\n",
    "\n",
    "overreport_prop = {}\n",
    "for data_id in overreport_df['data_id'].unique():\n",
    "    pop_df = pd.read_csv(f'../tmp/data/{data_id}/population.csv')\n",
    "    survey_df = pd.read_csv(f'../tmp/data/{data_id}/estonia_selection.csv')\n",
    "    combined_df = pd.merge(survey_df, pop_df, on=survey_cols, how='left', suffixes=('', '_pop'))\n",
    "    assert combined_df['outcome_pop'].isna().sum() == 0\n",
    "    overreport_diff = combined_df['outcome'].sum() - combined_df['outcome_pop'].sum()\n",
    "    overreport_prop[data_id] = overreport_diff / len(combined_df)\n",
    "\n",
    "overreport_df['overreport_prop'] = overreport_df['data_id'].apply(lambda id: overreport_prop[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6049581",
   "metadata": {},
   "outputs": [],
   "source": [
    "overreport_summary_df = aggregate_results(overreport_df, ['model_name', 'selection_bias_type', 'selection_bias'], list(variable_all_map.keys()))\n",
    "overreport_prop_df = aggregate_results(overreport_df, ['model_name', 'selection_bias_type', 'selection_bias'], ['overreport_prop'], functions={'mean': ['mean']}).drop(columns=['variable']).rename(columns={'mean': 'overreport_prop'})\n",
    "overreport_summary_df = pd.merge(overreport_summary_df, overreport_prop_df, on=['model_name', 'selection_bias_type', 'selection_bias'], how='left')\n",
    "\n",
    "aggregated_results_plot(\n",
    "    overreport_summary_df[overreport_summary_df['selection_bias_type'] == 'constant'],\n",
    "    'overreport_bias',\n",
    "    'overreport_prop',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Proportion of mis-reporting survey responders'},\n",
    "    figure_size=get_figure_size(width=5, ratio=2/3),\n",
    "    default_parameters=default_parameters,\n",
    "    facet_scales='free_y',\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.0)),\n",
    "    errorbar_width=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e576e9",
   "metadata": {},
   "source": [
    "### Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ad262",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcoef_cor_df = get_results(data_config, model_results_df, 'est-hcoef-cor', {'heckman_coef_kwargs/rho': 'heckman_coef_rho'})\n",
    "hcoef_cor_summary_df = aggregate_results(hcoef_cor_df, ['model_name', 'heckman_coef_rho'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    hcoef_cor_summary_df,\n",
    "    'hcoef_cor',\n",
    "    'heckman_coef_rho',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Selection and outcome process correlation ($\\\\rho_H$)'},\n",
    "    errorbar_width=0.025,\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.5)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64b027",
   "metadata": {},
   "source": [
    "### Non-normal errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_normal_error_df = get_results(data_config, model_results_df, 'est-non-normal-error', {'heckman_coef_kwargs/heckman_coefs/error/distribution': 'error_distribution', 'heckman_coef_kwargs/heckman_coefs/error/dof': 'error_dof', 'heckman_coef_kwargs/heckman_coefs/error/skew': 'error_skew'})\n",
    "non_normal_error_df['selection_skew'] = non_normal_error_df['error_skew'].apply(lambda x: x[0])\n",
    "non_normal_error_df['outcome_skew'] = non_normal_error_df['error_skew'].apply(lambda x: x[1])\n",
    "default_df = get_results(data_config, model_results_df, 'est-default')\n",
    "default_df['error_distribution'] = 'normal'\n",
    "\n",
    "non_normal_error_tail_df = pd.concat([\n",
    "    non_normal_error_df.loc[np.logical_and(non_normal_error_df['selection_skew'] == 0.0, non_normal_error_df['outcome_skew'] == 0.0)],\n",
    "    default_df,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c803e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_normal_error_tail_summary_df = aggregate_results(non_normal_error_tail_df, ['data_name', 'model_name', 'error_distribution'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    non_normal_error_tail_summary_df,\n",
    "    'non_normal_error_tail',\n",
    "    'error_distribution',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    scale_x_map={'normal': 'Normal', 'skewed_t': 'Student\\'s t'},\n",
    "    labs={'x': 'Heckman error distribution'},\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.75)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d26e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_normal_error_summary_df = aggregate_results(non_normal_error_df, ['model_name', 'selection_skew', 'outcome_skew'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    non_normal_error_summary_df,\n",
    "    'non_normal_error',\n",
    "    'model_name',\n",
    "    facet_cols=['selection_skew', 'outcome_skew'],\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    facet_maps={'selection_skew': {x: 'Sel: $\\\\gamma^s$ = %s' % x for x in non_normal_error_summary_df['selection_skew'].unique()}, 'outcome_skew': {x: 'Out: $\\\\gamma^o$ = %s' % x for x in non_normal_error_summary_df['outcome_skew'].unique()}},\n",
    "    labs={'x': ''},\n",
    "    errorbar_width=0.25,\n",
    "    figure_size=get_figure_size(width=7, ratio=1/2),\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.5)),\n",
    "    dodge_width=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1371e",
   "metadata": {},
   "source": [
    "### Error correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heck_cor_df = get_results(data_config, model_results_df, 'est-heck-cor', {'heckman_coef_kwargs/heckman_coefs/error/rho': 'heckman_rho'})\n",
    "heck_cor_summary_df = aggregate_results(heck_cor_df, ['model_name', 'heckman_rho'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    heck_cor_summary_df,\n",
    "    'heck_cor',\n",
    "    'heckman_rho',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Heckman error correlation'},\n",
    "    errorbar_width=0.025,\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.0)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d18ac5",
   "metadata": {},
   "source": [
    "### Selection and outcome effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcoef_sigma_df = get_results(data_config, model_results_df, 'est-hcoef-sigma', {'heckman_coef_kwargs/default_sigma/selection': 'selection_sigma', 'heckman_coef_kwargs/default_sigma/outcome': 'outcome_sigma'})\n",
    "hcoef_sigma_summary_df = aggregate_results(hcoef_sigma_df, ['model_name', 'selection_sigma', 'outcome_sigma'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    hcoef_sigma_summary_df,\n",
    "    'hcoef_sigma_outcome',\n",
    "    'model_name',\n",
    "    model_name_map=model_name_all_map, variable_map=get_map(variable_all_map, ['kld_2d']),\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    facet_cols=['selection_sigma', 'outcome_sigma'],\n",
    "    facet_maps={'selection_sigma': {x: 'Sel: $\\\\sigma_{H,S}$ = %s' % x for x in hcoef_sigma_df['selection_sigma'].unique()}, 'outcome_sigma': {x: 'Out: $\\\\sigma_{H,O}$ = %s' % x for x in hcoef_sigma_df['outcome_sigma'].unique()}},\n",
    "    labs={'x': ''},\n",
    "    errorbar_width=0.3,\n",
    "    figure_size=get_figure_size(width=7, ratio=2/3),\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.5), 10**(-0.5)),\n",
    "    dodge_width=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522db38b",
   "metadata": {},
   "source": [
    "### Selection and outcome effect interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data_df = get_results(data_config, model_results_df, 'est-int')\n",
    "\n",
    "int_model_names = [\n",
    "    '1_bp',\n",
    "    '2_ei',\n",
    "    '3_gg',\n",
    "    '4_pm',\n",
    "    '5_fs',\n",
    "    '1_int_bp',\n",
    "    '2_int_ei',\n",
    "    '3_int_gg',\n",
    "    '4_int_pm',\n",
    "    '5_int_fs',\n",
    "]\n",
    "\n",
    "int_name_map = {\n",
    "    \"1_int_bp\": \"1_bp\",\n",
    "    \"2_int_ei\": \"2_ei\",\n",
    "    \"3_int_gg\": \"3_gg\",\n",
    "    \"4_int_pm\": \"4_pm\",\n",
    "    \"5_int_fs\": \"5_fs\",\n",
    "}\n",
    "\n",
    "int_data_df['model_int'] = int_data_df['model_name'].apply(lambda x: x in int_name_map)\n",
    "int_data_df['model_name'] = int_data_df['model_name'].apply(lambda x: int_name_map[x] if x in int_name_map else x)\n",
    "int_data_df['data_int'] = True\n",
    "\n",
    "non_int_data_df = get_results(data_config, model_results_df, 'est-default')\n",
    "non_int_data_df = non_int_data_df[non_int_data_df['model_name'].isin(int_model_names)]\n",
    "non_int_data_df['model_int'] = non_int_data_df['model_name'].apply(lambda x: x in int_name_map)\n",
    "non_int_data_df['model_name'] = non_int_data_df['model_name'].apply(lambda x: int_name_map[x] if x in int_name_map else x)\n",
    "non_int_data_df['data_int'] = False\n",
    "\n",
    "int_df = pd.concat([int_data_df, non_int_data_df])\n",
    "int_df['interaction_case'] = int_df.apply(lambda row: f'{\"with_data_int\" if row[\"data_int\"] else \"without_data_int\"}-{\"with_model_int\" if row[\"model_int\"] else \"without_model_int\"}', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aedf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_summary_df = aggregate_results(int_df, ['model_name', 'model_int', 'data_int'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    int_summary_df,\n",
    "    'int',\n",
    "    'model_name',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Two-way interactions between inputs'},\n",
    "    facet_cols=['model_int', 'data_int'],\n",
    "    facet_maps={'model_int': {x: 'Model interactions' if x else 'No model interactions' for x in int_summary_df['model_int'].unique()}, \n",
    "    'data_int': {x: 'Data interactions' if x else 'No data interactions' for x in int_summary_df['data_int'].unique()}},\n",
    "    errorbar_width=0.15,\n",
    "    figure_size=get_figure_size(width=5, ratio=2/3),\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.75)),\n",
    "    dodge_width=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44425362",
   "metadata": {},
   "source": [
    "### Random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3814ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = get_results(data_config, model_results_df, 'est-noise', {'heckman_coef_kwargs/heckman_coefs/selection_noise_prop': 'selection_noise_prop', 'heckman_coef_kwargs/heckman_coefs/outcome_noise_prop': 'outcome_noise_prop'})\n",
    "noise_summary_df = aggregate_results(noise_df, ['model_name', 'selection_noise_prop', 'outcome_noise_prop'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    noise_summary_df,\n",
    "    'noise_outcome',\n",
    "    'model_name',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': ''},\n",
    "    facet_cols=['selection_noise_prop', 'outcome_noise_prop'],\n",
    "    facet_maps={'selection_noise_prop': {x: f'Sel. noise: {100*x:.0f}%' for x in noise_summary_df['selection_noise_prop'].unique()}, 'outcome_noise_prop': {x: f'Out. noise: {100*x:.0f}%' for x in noise_summary_df['outcome_noise_prop'].unique()}},\n",
    "    errorbar_width=0.15,\n",
    "    figure_size=get_figure_size(width=7, ratio=1/2),\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.5)),\n",
    "    dodge_width=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080dde86",
   "metadata": {},
   "source": [
    "### Sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20659647",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_df = get_results(data_config, model_results_df, 'est-sample-size', {'selection_kwargs/sample_size': 'sample_size'})\n",
    "sample_size_summary_df = aggregate_results(sample_size_df, ['model_name', 'sample_size'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    sample_size_summary_df,\n",
    "    'sample_size',\n",
    "    'sample_size',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Sample size'},\n",
    "    errorbar_width=50,\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.75)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556bfee",
   "metadata": {},
   "source": [
    "### Prior scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_model_names = [\n",
    "    '1_bp',\n",
    "    '2_ei',\n",
    "    '3_gg',\n",
    "    '4_pm',\n",
    "    '5_fs',\n",
    "    '1_scale_bp',\n",
    "    '2_scale_ei',\n",
    "    '3_scale_gg',\n",
    "    '4_scale_pm',\n",
    "    '5_scale_fs'\n",
    "]\n",
    "\n",
    "scale_name_map = {\n",
    "    '1_scale_bp': '1_bp',\n",
    "    '2_scale_ei': '2_ei',\n",
    "    '3_scale_gg': '3_gg',\n",
    "    '4_scale_pm': '4_pm',\n",
    "    '5_scale_fs': '5_fs',\n",
    "}\n",
    "\n",
    "prior_df = get_results(data_config, model_results_df, 'est-default')\n",
    "prior_df = prior_df[prior_df['model_name'].isin(scale_model_names)]\n",
    "prior_df['model_prior_scale'] = prior_df['model_name'].apply(lambda x: x in scale_name_map)\n",
    "prior_df['model_name'] = prior_df['model_name'].apply(lambda x: scale_name_map[x] if x in scale_name_map else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a319f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_summary_df = aggregate_results(prior_df, ['model_name', 'model_prior_scale'], list(variable_all_map.keys()))\n",
    "\n",
    "aggregated_results_plot(\n",
    "    prior_summary_df,\n",
    "    'prior_scale',\n",
    "    'model_prior_scale',\n",
    "    model_name_map=model_name_all_map, variable_map=variable_map,\n",
    "    model_color_map=model_color_map, model_shape_map=model_shape_map,\n",
    "    labs={'x': 'Prior type'},\n",
    "    scale_x_map={False: 'Weakly informative priors', True: 'Strongly informative priors'},\n",
    "    errorbar_width=0.05,\n",
    "    figure_size=get_figure_size(width=5, ratio=2/3),\n",
    "    default_parameters=default_parameters,\n",
    "    scale_y='log',\n",
    "    y_limits=(10**(-3.0), 10**(-0.75)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3755576",
   "metadata": {},
   "source": [
    "### Divergences and R-hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bab4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.float_format','{:,.2f}'.format)\n",
    "\n",
    "def config_without_seed(config, data_id):\n",
    "    conf = dict(config[data_id])\n",
    "    del conf['seed']\n",
    "    return ','.join([f'{key}={value}' for key, value in conf.items()])\n",
    "\n",
    "def get_description(df, cols):\n",
    "    data_df = df.copy()\n",
    "    data_df['description'] = data_df.apply(lambda row: row['data_name'] + '[' + ', '.join([f'{col}={row[col]}' for col in cols]) + ']', axis=1)\n",
    "    return data_df\n",
    "\n",
    "results_df = pd.concat([\n",
    "    get_description(default_df, []),\n",
    "    get_description(agg_bias_df, ['agg_bias']),\n",
    "    get_description(no_selection_df, ['data_has_selection']),\n",
    "    get_description(non_response_df, ['selection_intercept']),\n",
    "    get_description(margin_df, ['model_margin']),\n",
    "    get_description(overreport_df, ['selection_bias_type', 'selection_bias']),\n",
    "    get_description(hcoef_cor_df, ['heckman_coef_rho']),\n",
    "    get_description(non_normal_error_tail_df, ['error_distribution']),\n",
    "    get_description(non_normal_error_df, ['selection_skew', 'outcome_skew']),\n",
    "    get_description(heck_cor_df, ['heckman_rho']),\n",
    "    get_description(hcoef_sigma_df, ['selection_sigma', 'outcome_sigma']),\n",
    "    get_description(int_df, ['model_int', 'data_int']),\n",
    "    get_description(noise_df, ['selection_noise_prop', 'outcome_noise_prop']),\n",
    "    get_description(sample_size_df, ['sample_size']),\n",
    "    get_description(prior_df, ['model_prior_scale']),\n",
    "])\n",
    "\n",
    "#model_results_df.groupby(['data_name', 'description', 'model_name']).divergences.agg(['mean', 'std', 'median', 'min', 'max'])\n",
    "#model_results_df.groupb\n",
    "\n",
    "#pd.pivot_table(model_results_df, values='divergences', index=['data_name', 'description', 'model_name'], aggfunc='median')\n",
    "\n",
    "def model_name_remap(model_name):\n",
    "    if model_name.endswith('_bp'):\n",
    "        return '01_bp'\n",
    "    elif model_name.endswith('_ei'):\n",
    "        return '02_ei'\n",
    "    elif model_name.endswith('_gg'):\n",
    "        return '03_gg'\n",
    "    elif model_name.endswith('_pm'):\n",
    "        return '04_pm'\n",
    "    elif model_name.endswith('_fs'):\n",
    "        return '05_fs'\n",
    "\n",
    "\n",
    "results_df['model_name_s'] = results_df['model_name'].apply(model_name_remap)\n",
    "\n",
    "#results_df.loc[results_df['model_name_s'] == '2_ei', 'divergences'] = results_df.loc[results_df['model_name_s'] == '2_ei', 'divergences'] / 2.0\n",
    "#results_df.loc[results_df['model_name_s'] == '10_pmdei', 'divergences'] = results_df.loc[results_df['model_name_s'] == '10_pmdei', 'divergences'] / 2.0\n",
    "\n",
    "(\n",
    "    p9.ggplot(results_df.groupby(['description', 'model_name_s']).divergences.median().reset_index(), p9.aes(y='description', x='model_name_s', fill='divergences'))\n",
    "    + p9.geom_tile(width=0.95, height=0.95)\n",
    "    + p9.geom_text(p9.aes(label='divergences'), color='black')\n",
    "    + p9.scale_fill_gradientn(colors=sns.color_palette(\"RdYlGn_r\", 100))\n",
    "    + p9.theme(\n",
    "        figure_size=get_figure_size(width=12, ratio=1.0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be900e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(results_df.groupby(['description', 'model_name_s']).mean_rhat.median().round(3).reset_index(), p9.aes(y='description', x='model_name_s', fill='mean_rhat'))\n",
    "    + p9.geom_tile(width=0.95, height=0.95)\n",
    "    + p9.geom_text(p9.aes(label='mean_rhat'), color='black')\n",
    "    + p9.scale_fill_gradientn(colors=sns.color_palette(\"RdYlGn_r\", 100))\n",
    "    + p9.theme(\n",
    "        figure_size=get_figure_size(width=14, ratio=1.0),\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
