{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e851897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import hashlib\n",
    "import itertools\n",
    "import importlib\n",
    "import json\n",
    "import scipy.stats as st\n",
    "import sklarpy.multivariate\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings from sklarpy\n",
    "warnings.filterwarnings('ignore', module='sklarpy.multivariate', message='divide by zero encountered in matmul')\n",
    "warnings.filterwarnings('ignore', module='sklarpy.multivariate', message='overflow encountered in matmul')\n",
    "warnings.filterwarnings('ignore', module='sklarpy.multivariate', message='invalid value encountered in matmul')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fecabd8",
   "metadata": {},
   "source": [
    "## Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f269a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_state(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    heckman_seed = np.random.randint(0, 1000000)\n",
    "    uniform_seed = np.random.randint(0, 1000000)\n",
    "    selection_seed = np.random.randint(0, 1000000)\n",
    "    heckman_coefs_seed = np.random.randint(0, 1000000)\n",
    "\n",
    "    return {\n",
    "        'HECKMAN_SEED': heckman_seed,\n",
    "        'UNIFORM_SEED': uniform_seed,\n",
    "        'SELECTION_SEED': selection_seed,\n",
    "        'HECKMAN_COEFS_SEED': heckman_coefs_seed,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7602db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 20250924\n",
    "RANDOM_ALT_SEED = 20240924\n",
    "\n",
    "RANDOM_STATE = get_random_state(RANDOM_SEED)\n",
    "RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611de7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_dtype = {col: 'category' for col in ['age_group', 'education', 'gender', 'nationality', 'electoral_district', 'unit']}\n",
    "census_df = pd.read_csv('../data/census.csv', dtype=census_dtype)\n",
    "census_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = census_df.loc[census_df.index.repeat(census_df.N)].drop(columns=['N']).reset_index(drop=True)\n",
    "demography_cols = sorted(population_df.columns.tolist())\n",
    "print(population_df.shape)\n",
    "population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2599e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_margins(df, columns=None, outcome=None):\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "\n",
    "    if outcome is None:\n",
    "        return df.groupby(columns, observed=False).size() / len(df)\n",
    "    else:\n",
    "        return df.groupby(columns, observed=False)[outcome].sum() / len(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(df, column):\n",
    "    categories = []\n",
    "\n",
    "    if ':' in column:\n",
    "        col1, col2 = column.split(':')\n",
    "\n",
    "        is_col1_cat = col1 in df.columns and df[col1].dtype == 'category'\n",
    "        is_col2_cat = col2 in df.columns and df[col2].dtype == 'category'\n",
    "\n",
    "        if is_col1_cat and is_col2_cat:\n",
    "            categories = list(map(lambda cats: f'{cats[0]}:{cats[1]}', itertools.product(df[col1].cat.categories.values, df[col2].cat.categories.values)))\n",
    "        elif is_col1_cat:\n",
    "            categories = df[col1].cat.categories.values\n",
    "        elif is_col2_cat:\n",
    "            categories = df[col2].cat.categories.values\n",
    "    else:\n",
    "        if column in df.columns and df[column].dtype == 'category':\n",
    "            categories = df[column].cat.categories.values\n",
    "\n",
    "    return categories\n",
    "\n",
    "def set_if_new_and_return(config, path, default):\n",
    "    path_keys = path.split('/')\n",
    "    current_config = config\n",
    "\n",
    "    for key in path_keys[:-1]:\n",
    "        if key not in current_config:\n",
    "            current_config[key] = {}\n",
    "        current_config = current_config[key]\n",
    "\n",
    "    if path_keys[-1] not in current_config:\n",
    "        current_config[path_keys[-1]] = default\n",
    "\n",
    "    return current_config[path_keys[-1]]\n",
    "\n",
    "def generate_heckman_coefs(df, selection_columns, outcome_columns, default_sigma, rho, heckman_coefs, multilevel=True, seed=RANDOM_STATE['HECKMAN_COEFS_SEED']):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    coefs = copy.deepcopy(heckman_coefs)\n",
    "    columns = sorted(list(set(selection_columns) | set(outcome_columns)))\n",
    "\n",
    "    set_if_new_and_return(coefs, 'selection/intercept', 0)\n",
    "    set_if_new_and_return(coefs, 'outcome/intercept', 0)\n",
    "\n",
    "    for column in columns:\n",
    "        categories = get_categories(df, column)\n",
    "\n",
    "        s_sigma = default_sigma['selection_interaction'] if ':' in column else default_sigma['selection']\n",
    "        o_sigma = default_sigma['outcome_interaction'] if ':' in column else default_sigma['outcome']\n",
    "\n",
    "        # Generate values for tau, even if we don't use them for consistency\n",
    "        s_tau_val = st.halfnorm.rvs(scale=s_sigma)\n",
    "        o_tau_val = st.halfnorm.rvs(scale=o_sigma)\n",
    "\n",
    "        if multilevel:\n",
    "            s_tau = set_if_new_and_return(coefs, f'selection/tau/{column}', s_tau_val)\n",
    "            o_tau = set_if_new_and_return(coefs, f'outcome/tau/{column}', o_tau_val)\n",
    "            cov_matrix = np.diag([s_tau, o_tau]) @ np.array([[1, rho], [rho, 1]]) @ np.diag([s_tau, o_tau])\n",
    "        else:\n",
    "            cov_matrix = np.diag([s_sigma, o_sigma]) @ np.array([[1, rho], [rho, 1]]) @ np.diag([s_sigma, o_sigma])\n",
    "\n",
    "        if len(categories) > 0:\n",
    "            gen_coefs = np.random.multivariate_normal(np.zeros(2), cov_matrix, size=len(categories))\n",
    "            gen_coefs = gen_coefs - gen_coefs.mean(axis=0)\n",
    "            if column in selection_columns:\n",
    "                col_coefs = set_if_new_and_return(coefs, f'selection/beta/{column}', {})\n",
    "\n",
    "                for i, cat in enumerate(categories):\n",
    "                    coef = gen_coefs[i, 0].item()\n",
    "                    if cat not in col_coefs:\n",
    "                        col_coefs[cat] = coef\n",
    "\n",
    "                assert len(col_coefs) == len(categories)\n",
    "\n",
    "                coefs['selection']['beta'][column] = col_coefs\n",
    "            if column in outcome_columns:\n",
    "                col_coefs = set_if_new_and_return(coefs, f'outcome/beta/{column}', {})\n",
    "\n",
    "                for i, cat in enumerate(categories):\n",
    "                    coef = gen_coefs[i, 1].item()\n",
    "                    if cat not in col_coefs:\n",
    "                        col_coefs[cat] = coef\n",
    "\n",
    "                assert len(col_coefs) == len(categories)\n",
    "\n",
    "                coefs['outcome']['beta'][column] = col_coefs\n",
    "        else:\n",
    "            gen_coefs = np.random.multivariate_normal(np.zeros(2), cov_matrix, size=1)\n",
    "            if column in selection_columns:\n",
    "                set_if_new_and_return(coefs, f'selection/beta/{column}', gen_coefs[0, 0].item())\n",
    "            if column in outcome_columns:\n",
    "                set_if_new_and_return(coefs, f'outcome/beta/{column}', gen_coefs[0, 1].item())\n",
    "\n",
    "    return coefs\n",
    "\n",
    "def validate_column(df, column, ignore_columns=[]):\n",
    "    if column in ignore_columns:\n",
    "        return\n",
    "\n",
    "    assert column in df.columns, f\"{column} not in {df.columns}\"\n",
    "    assert df[column].dtype == 'category', f\"{column} is not of type category: {df[column].dtype}\"\n",
    "\n",
    "def validate_coefs(df, column, coefs, ignore_columns=[]):\n",
    "    if column in ignore_columns:\n",
    "        return\n",
    "\n",
    "    if column in coefs:\n",
    "        for cat in coefs[column]:\n",
    "            assert cat in df[column].cat.categories, f\"{cat} not in {df[column].cat.categories}\"\n",
    "\n",
    "def get_cov_matrix(rho, sigma):\n",
    "    return np.array([[1.0, rho*sigma], [rho*sigma, sigma**2]])\n",
    "\n",
    "def heckman_model(df, coefs={}, seed=RANDOM_STATE['HECKMAN_SEED']):\n",
    "    np.random.seed(seed)\n",
    "    df = df.copy()\n",
    "\n",
    "    selection_process = coefs.get('selection', {})\n",
    "    outcome_process = coefs.get('outcome', {})\n",
    "\n",
    "    selection_beta = selection_process.get('beta', {})\n",
    "    outcome_beta = outcome_process.get('beta', {})\n",
    "\n",
    "    selection_noise_prop = coefs.get('selection_noise_prop', 0.0)\n",
    "    outcome_noise_prop = coefs.get('outcome_noise_prop', 0.0)\n",
    "    random_noise_prop = coefs.get('random_noise_prop', 0.5)\n",
    "\n",
    "    error_params = coefs.get('error', {})\n",
    "\n",
    "    selection_columns = set(selection_beta.keys())\n",
    "    outcome_columns = set(outcome_beta.keys())\n",
    "\n",
    "    for column in selection_columns:\n",
    "        if ':' in column:\n",
    "            col1, col2 = column.split(':')\n",
    "            validate_column(df, col1)\n",
    "            validate_column(df, col2)\n",
    "            validate_coefs(df, col1, selection_beta)\n",
    "            validate_coefs(df, col2, selection_beta)\n",
    "        else:\n",
    "            validate_column(df, column)\n",
    "            validate_coefs(df, column, selection_beta)\n",
    "\n",
    "    special_selection_columns = ['selection_mean', 'selection_error', 'selection_latent', 'selection']\n",
    "\n",
    "    for column in outcome_columns:\n",
    "        if ':' in column:\n",
    "            col1, col2 = column.split(':')\n",
    "            validate_column(df, col1, ignore_columns=special_selection_columns)\n",
    "            validate_column(df, col2, ignore_columns=special_selection_columns)\n",
    "            validate_coefs(df, col1, outcome_beta, ignore_columns=special_selection_columns)\n",
    "            validate_coefs(df, col2, outcome_beta, ignore_columns=special_selection_columns)\n",
    "        else:\n",
    "            validate_column(df, column, ignore_columns=special_selection_columns)\n",
    "            validate_coefs(df, column, outcome_beta, ignore_columns=special_selection_columns)\n",
    "\n",
    "    df['selection_mean'] = np.full(len(df), selection_process.get('intercept', 0)).astype(float)\n",
    "    df['outcome_mean'] = np.full(len(df), outcome_process.get('intercept', 0)).astype(float)\n",
    "\n",
    "    match error_dist := error_params.get('distribution', 'normal'):\n",
    "        case 'normal':\n",
    "            error_mean = error_params.get('mean', [0., 0.])\n",
    "            error_rho = error_params.get('rho', 0.5)\n",
    "            error_sigma = error_params.get('sigma', 1.0)\n",
    "            errors = np.random.multivariate_normal(error_mean, get_cov_matrix(rho=error_rho, sigma=error_sigma), size=len(df))\n",
    "        case 'skewed_t':\n",
    "            error_mean = error_params.get('mean', [0., 0.])\n",
    "            error_rho = error_params.get('rho', 0.5)\n",
    "            error_sigma = error_params.get('sigma', 1.0)\n",
    "            error_dof = error_params.get('dof', 5.0)\n",
    "            error_skew = error_params.get('skew', [0.0, 0.0])\n",
    "            # https://sklarpy.readthedocs.io/en/latest/Multivariate.html#multivariate-example \n",
    "            skewed_t_params = (error_dof, np.array(error_mean), get_cov_matrix(rho=error_rho, sigma=error_sigma), np.array(error_skew))\n",
    "            errors = sklarpy.multivariate.mvt_skewed_t.rvs(size=len(df), params=skewed_t_params)\n",
    "        case _:\n",
    "            raise ValueError(f'Invalid error distribution: {error_dist}')\n",
    "\n",
    "    df['selection_error'] = errors[:, 0]\n",
    "    df['outcome_error'] = errors[:, 1]\n",
    "\n",
    "    df['use_selection_noise'] = np.random.binomial(1, selection_noise_prop, size=len(df))\n",
    "    df['use_outcome_noise'] = np.random.binomial(1, outcome_noise_prop, size=len(df))\n",
    "\n",
    "    for column in selection_columns:\n",
    "        if ':' in column:\n",
    "            col1, col2 = column.split(':')\n",
    "            df['selection_mean'] += df[[col1, col2]].apply(lambda row: selection_beta.get(column, {}).get(f'{row[col1]}:{row[col2]}', 0), axis=1).values.astype(float)\n",
    "        else:\n",
    "            df['selection_mean'] += df[column].apply(lambda cat: selection_beta.get(column, {}).get(cat, 0)).values.astype(float)\n",
    "\n",
    "    df['selection_latent'] = df['selection_mean'] + df['selection_error']\n",
    "    df['selection'] = np.where(\n",
    "        df['use_selection_noise'],\n",
    "        np.random.binomial(1, random_noise_prop, size=len(df)).astype(int),\n",
    "        (df['selection_latent'] > 0).astype(int)\n",
    "    )\n",
    "\n",
    "    for column in outcome_columns:\n",
    "        if ':' in column:\n",
    "            col1, col2 = column.split(':')\n",
    "            if col1 in special_selection_columns and col2 in special_selection_columns:\n",
    "                df['outcome_mean'] += df[col1] * df[col2] * outcome_beta.get(column, 0)\n",
    "            elif col1 in special_selection_columns:\n",
    "                df['outcome_mean'] += df[col1] * df[col2].apply(lambda cat: outcome_beta.get(column, {}).get(cat, 0)).values.astype(float)\n",
    "            elif col2 in special_selection_columns:\n",
    "                df['outcome_mean'] += df[col2] * df[col1].apply(lambda cat: outcome_beta.get(column, {}).get(cat, 0)).values.astype(float)\n",
    "            else:\n",
    "                df['outcome_mean'] += df[[col1, col2]].apply(lambda row: outcome_beta.get(column, {}).get(f'{row[col1]}:{row[col2]}', 0), axis=1).values.astype(float)\n",
    "        else:\n",
    "            if column in special_selection_columns:\n",
    "                df['outcome_mean'] += df[column] * outcome_beta.get(column, 0)\n",
    "            else:\n",
    "                df['outcome_mean'] += df[column].apply(lambda cat: outcome_beta.get(column, {}).get(cat, 0)).values.astype(float)\n",
    "\n",
    "    df['outcome_latent'] = df['outcome_mean'] + df['outcome_error']\n",
    "    df['outcome'] = np.where(\n",
    "        df['use_outcome_noise'],\n",
    "        np.random.binomial(1, random_noise_prop, size=len(df)).astype(int),\n",
    "        (df['outcome_latent'] > 0).astype(int)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def col_margins(df, columns, outcome):\n",
    "    groups = df.groupby(columns, observed=False)\n",
    "    return (groups[outcome].value_counts() / groups.size()).rename('proportion').reset_index()\n",
    "\n",
    "def aggregation_bias(df, agg_cols, coefs={}):\n",
    "    df = df.copy()\n",
    "    df['agg_bias'] = 0\n",
    "\n",
    "    for coef_col in coefs:\n",
    "        margin_col = f'{\"_\".join(sorted(agg_cols))}_{coef_col}_margin'\n",
    "        margin = col_margins(df, agg_cols, coef_col).rename(columns={'proportion': margin_col})\n",
    "        df = pd.merge(df, margin, on=agg_cols + [coef_col], how='left')\n",
    "        df['agg_bias'] += df[margin_col] * df[coef_col].apply(lambda cat: coefs.get(coef_col, {}).get(cat, 0)).values.astype(float)\n",
    "\n",
    "    df['outcome_latent'] = df['outcome_mean'] + df['outcome_error'] + df['agg_bias']\n",
    "    df['outcome'] = np.where(df['use_outcome_noise'], df['outcome'], (df['outcome_latent'] > 0).astype(int))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47eeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_sample(df, sample_size, bias={}, seed=RANDOM_STATE['SELECTION_SEED']):\n",
    "    np.random.seed(seed)\n",
    "    sample_df = df.sample(sample_size, weights='selection')\n",
    "\n",
    "    match bias_type := bias.get('type', 'constant'):\n",
    "        case 'constant':\n",
    "            sample_df['outcome_latent'] = sample_df['outcome_latent'] + bias.get('offset', 0.0)\n",
    "        case 'dynamic':\n",
    "            sample_df['outcome_latent'] = sample_df['outcome_latent'] + np.where(sample_df['outcome_mean'] >= 0, sample_df['outcome_mean'], 0) * bias.get('coef', 0.0)\n",
    "        case _:\n",
    "            raise ValueError(f'Invalid bias type: {bias_type}')\n",
    "\n",
    "    sample_df['outcome'] = np.where(\n",
    "        sample_df['use_outcome_noise'],\n",
    "        sample_df['outcome'],\n",
    "        (sample_df['outcome_latent'] > 0).astype(int)\n",
    "    )\n",
    "    return sample_df\n",
    "\n",
    "def generate_data(out_prefix, config, population_df, margin_cols, template_prefix='../data', template_files=[]):\n",
    "    out_path = pathlib.Path(out_prefix)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config['seed'] = config.get('seed', RANDOM_SEED)\n",
    "    rng_state = get_random_state(config['seed'])\n",
    "    config['heckman_coef_kwargs']['seed'] = config['heckman_coef_kwargs'].get('seed', rng_state['HECKMAN_COEFS_SEED'])\n",
    "    config['selection_kwargs']['seed'] = config['selection_kwargs'].get('seed', rng_state['SELECTION_SEED'])\n",
    "    config['heckman_kwargs']['seed'] = config['heckman_kwargs'].get('seed', rng_state['HECKMAN_SEED'])\n",
    "\n",
    "    with open(out_path / 'data_config.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    heckman_coef_kwargs = config.get('heckman_coef_kwargs', {})\n",
    "    heckman_kwargs = config.get('heckman_kwargs', {})\n",
    "    selection_kwargs = config.get('selection_kwargs', {})\n",
    "    aggregation_bias_kwargs = config.get('aggregation_bias_kwargs', None)\n",
    "\n",
    "    for filename in template_files:\n",
    "        shutil.copyfile(pathlib.Path(template_prefix) / filename, out_path / filename)\n",
    "\n",
    "    heckman_coefs = generate_heckman_coefs(population_df, **heckman_coef_kwargs)\n",
    "    heckman_df = heckman_model(population_df, coefs=heckman_coefs, **heckman_kwargs)\n",
    "    if aggregation_bias_kwargs is not None: heckman_df = aggregation_bias(heckman_df, **aggregation_bias_kwargs)\n",
    "    heckman_df['voting_intent'] = heckman_df['outcome'].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "    # Keep population compact: parquet + no latent columns\n",
    "    keep_columns = population_df.columns.tolist() + [\n",
    "        'voting_intent', 'selection', 'outcome',\n",
    "    ]\n",
    "    drop_columns = [col for col in heckman_df.columns if col not in keep_columns]\n",
    "\n",
    "    pop_out_df = heckman_df.drop(columns=drop_columns)\n",
    "    latent_cols = [c for c in pop_out_df.columns if 'latent' in c]\n",
    "    pop_out_df = pop_out_df.drop(columns=latent_cols, errors='ignore')\n",
    "\n",
    "    # Ensure categoricals are stored as categoricals in parquet (round-trips on read_parquet)\n",
    "    for col in population_df.columns.tolist() + ['voting_intent']:\n",
    "        if col in pop_out_df.columns and str(pop_out_df[col].dtype) != 'category':\n",
    "            pop_out_df[col] = pop_out_df[col].astype('category')\n",
    "\n",
    "    pop_out_df.to_parquet(out_path / 'population.parquet', index=False)\n",
    "\n",
    "    selection_sample_df = selection_sample(heckman_df, **selection_kwargs)\n",
    "    selection_sample_df['voting_intent'] = selection_sample_df['outcome'].map({1: 'Yes', 0: 'No'})\n",
    "    selection_sample_df.drop(columns=drop_columns).to_csv(out_path / 'estonia_selection.csv', index=False, float_format='%.4f')\n",
    "\n",
    "    for cols in margin_cols:\n",
    "        heckman_margin_df = df_margins(heckman_df, columns=cols + ['voting_intent']).fillna(0).reset_index(name='proportion')\n",
    "        heckman_margin_df['N'] = (heckman_margin_df['proportion'] * len(heckman_df)).round(0).astype(int)\n",
    "        margin_file_name = f'estonia_{\"_\".join(sorted(cols))}_margins.csv' if len(cols) > 0 else 'estonia_margins.csv'\n",
    "        heckman_margin_df.drop(columns=['proportion']).to_csv(out_path / margin_file_name, index=False, float_format='%.4f')\n",
    "\n",
    "    with open(out_path / 'heckman_coefs.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(heckman_coefs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return heckman_df, selection_sample_df\n",
    "\n",
    "def translate_config_paths(config):\n",
    "    new_config = {}\n",
    "\n",
    "    for path_str, value in config.items():\n",
    "        current_config = new_config\n",
    "        keys = path_str.split('/')\n",
    "\n",
    "        for key in keys[:-1]:\n",
    "            current_config[key] = current_config.get(key, {})\n",
    "            current_config = current_config[key]\n",
    "\n",
    "        current_config[keys[-1]] = value\n",
    "\n",
    "    return new_config\n",
    "\n",
    "def apply_config(base_config, new_config):\n",
    "    if isinstance(base_config, dict) and isinstance(new_config, dict):\n",
    "        for key, value in base_config.items():\n",
    "            if key in new_config:\n",
    "                base_config[key] = apply_config(value, new_config[key])\n",
    "        \n",
    "        for key, value in new_config.items():\n",
    "            if key not in base_config:\n",
    "                base_config[key] = value\n",
    "    else:\n",
    "        base_config = new_config\n",
    "    \n",
    "    return base_config\n",
    "\n",
    "def generate_data_configs(configs, default_config):\n",
    "    if isinstance(configs, dict):\n",
    "        for config_vals in itertools.product(*configs.values()):\n",
    "            config = dict(zip(configs.keys(), config_vals))\n",
    "            yield (config, apply_config(copy.deepcopy(default_config), translate_config_paths(config)))\n",
    "    elif isinstance(configs, list):\n",
    "        for config in configs:\n",
    "            yield ('', apply_config(copy.deepcopy(default_config), config))\n",
    "    else:\n",
    "        raise ValueError(f'Invalid configs type: {type(configs)}')\n",
    "\n",
    "def get_n_seeds(initial_seed, n_seeds):\n",
    "    return [initial_seed + i for i in range(n_seeds)]\n",
    "\n",
    "def create_symlink(target_path, link_path):\n",
    "    if isinstance(link_path, str):\n",
    "        link_path = pathlib.Path(link_path)\n",
    "\n",
    "    if link_path.is_symlink():\n",
    "        os.unlink(link_path)\n",
    "    os.symlink(target_path, link_path)\n",
    "\n",
    "margin_cols = [[]] + [[col] for col in demography_cols] + [[c1, c2] for c1, c2 in itertools.combinations(demography_cols, 2)]\n",
    "input_cols = [col for col in demography_cols if col != 'electoral_district']\n",
    "\n",
    "heckman_selection_columns = list(input_cols)\n",
    "heckman_outcome_columns = list(input_cols)\n",
    "heckman_coef_columns = sorted(list(set(heckman_selection_columns) | set(heckman_outcome_columns)))\n",
    "\n",
    "heckman_selection_interactions = [f'{c1}:{c2}' for c1, c2 in itertools.combinations(heckman_selection_columns, 2)]\n",
    "heckman_outcome_interactions = [f'{c1}:{c2}' for c1, c2 in itertools.combinations(heckman_outcome_columns, 2)]\n",
    "\n",
    "heckman_coef_kwargs = {\n",
    "    'selection_columns': heckman_selection_columns,\n",
    "    'outcome_columns': heckman_outcome_columns,\n",
    "    'default_sigma': {\n",
    "        # Standard deviation of the half-normal distribution where the group-level standard deviation is drawn from\n",
    "        # Average is sigma * sqrt(2) / sqrt(pi) or approximately 0.8 * sigma\n",
    "        'selection': 0.5,\n",
    "        'outcome': 0.5,\n",
    "    },\n",
    "    'rho': 0.0,\n",
    "    'heckman_coefs': {\n",
    "        'selection': {'intercept': -1.0},\n",
    "        'outcome': {'intercept': 0.0},\n",
    "        'error': {\n",
    "            'distribution': 'normal',\n",
    "            'mean': [0., 0.],\n",
    "            'rho': 0.5,\n",
    "            'sigma': 1.0,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "default_config = {\n",
    "    'heckman_coef_kwargs': heckman_coef_kwargs,\n",
    "    'selection_kwargs': {'sample_size': 1000},\n",
    "    'heckman_kwargs': {},\n",
    "    'seed': RANDOM_SEED,\n",
    "}\n",
    "\n",
    "n_seeds = 5\n",
    "seeds_config = {'seed': get_n_seeds(RANDOM_SEED, n_seeds)[::-1]}\n",
    "\n",
    "generated_data_configs = {\n",
    "    'est-default': generate_data_configs({} | seeds_config, default_config),\n",
    "    'est-default-alt': generate_data_configs(\n",
    "        {\n",
    "            'seed': [RANDOM_ALT_SEED],\n",
    "            'heckman_coef_kwargs/seed': [get_random_state(RANDOM_SEED)['HECKMAN_COEFS_SEED']],\n",
    "        }, default_config),\n",
    "    'est-electoral-district': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/selection_columns': [demography_cols],\n",
    "            'heckman_coef_kwargs/outcome_columns': [demography_cols],\n",
    "        } | seeds_config, default_config),\n",
    "    'est-agg-bias': generate_data_configs(\n",
    "        {\n",
    "            'aggregation_bias_kwargs/agg_cols': [['unit']],\n",
    "            'aggregation_bias_kwargs/coefs': [{'nationality': {'Estonian': 0.0, 'Other': bias}} for bias in [0.0, 0.5, 1.0, 2.0]],\n",
    "        } | seeds_config, default_config),\n",
    "    'est-no-selection': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/selection_columns': [[]],\n",
    "            'heckman_coef_kwargs/heckman_coefs/rho': [0.0]\n",
    "        } | seeds_config, default_config),\n",
    "    'est-hcoef-cor': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/rho': [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "        } | seeds_config, default_config),\n",
    "    'est-hcoef-sigma': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/default_sigma/selection': [0.1, 0.5, 1.0, 2.0],\n",
    "            'heckman_coef_kwargs/default_sigma/outcome': [0.1, 0.5, 1.0, 2.0]\n",
    "        } | seeds_config, default_config),\n",
    "    'est-heck-cor': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/heckman_coefs/error/rho': [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "        } | seeds_config, default_config),\n",
    "    'est-sample-size': generate_data_configs(\n",
    "        {\n",
    "            'selection_kwargs/sample_size': [100, 250, 500, 1000, 2000]\n",
    "        } | seeds_config, default_config),\n",
    "    'est-overreport-const': generate_data_configs(\n",
    "        {\n",
    "            'selection_kwargs/bias/type': ['constant'],\n",
    "            'selection_kwargs/bias/offset': [0.0, 0.25, 0.5, 1.0],\n",
    "        } | seeds_config, default_config),\n",
    "    'est-non-response': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/heckman_coefs/selection/intercept': [-3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0],\n",
    "        } | seeds_config, default_config),\n",
    "    'est-int': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/selection_columns': [heckman_selection_columns + heckman_selection_interactions],\n",
    "            'heckman_coef_kwargs/outcome_columns': [heckman_outcome_columns + heckman_outcome_interactions],\n",
    "            'heckman_coef_kwargs/default_sigma/selection_interaction': [0.5],\n",
    "            'heckman_coef_kwargs/default_sigma/outcome_interaction': [0.5],\n",
    "        } | seeds_config, default_config),\n",
    "    'est-noise': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/heckman_coefs/selection_noise_prop': [0.00, 0.10, 0.20],\n",
    "            'heckman_coef_kwargs/heckman_coefs/outcome_noise_prop': [0.00, 0.10, 0.20],\n",
    "        } | seeds_config, default_config),\n",
    "    # Generating this configuration is very slow\n",
    "    'est-non-normal-error': generate_data_configs(\n",
    "        {\n",
    "            'heckman_coef_kwargs/heckman_coefs/error/distribution': ['skewed_t'],\n",
    "            'heckman_coef_kwargs/heckman_coefs/error/dof': [5.0],\n",
    "            'heckman_coef_kwargs/heckman_coefs/error/skew': [[s_skew, o_skew] for s_skew in [-1.0, 0.0, 1.0] for o_skew in [-1.0, 0.0, 1.0]],\n",
    "        } | seeds_config, default_config),\n",
    "}\n",
    "\n",
    "out_path = pathlib.Path('../tmp/data')\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "names = {}\n",
    "\n",
    "progress = tqdm(generated_data_configs.items())\n",
    "for name, configs in progress:\n",
    "    data_names = []\n",
    "\n",
    "    inner_progress = tqdm(configs, leave=False, total=n_seeds)\n",
    "    for desc, config in inner_progress:\n",
    "        data_id = hashlib.md5(json.dumps(config, sort_keys=True).encode('utf-8')).hexdigest()\n",
    "        data_name = f'{name}-{data_id}'\n",
    "        data_path = out_path / data_id\n",
    "\n",
    "        progress.set_postfix({'name': name, 'id': data_id, 'desc': desc})\n",
    "        inner_progress.set_postfix({'desc': desc, 'id': data_id})\n",
    "\n",
    "        generate_data(str(data_path), config, population_df, margin_cols)\n",
    "        data_names.append((data_name, desc))\n",
    "\n",
    "        link_path = out_path / data_name\n",
    "        if not link_path.exists():\n",
    "            os.symlink(data_path.name, link_path)\n",
    "\n",
    "        link_path = out_path / name\n",
    "        if link_path.exists() and link_path.is_symlink():\n",
    "            os.unlink(link_path)\n",
    "        os.symlink(data_path.name, link_path)\n",
    "\n",
    "    names[name] = data_names\n",
    "\n",
    "data_names_path = out_path / f'{datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}_data_list.json'\n",
    "with open(data_names_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(names, f, ensure_ascii=False, indent=2)\n",
    "create_symlink(data_names_path.name, out_path / 'data_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448b74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
